---
title: 'Problem Set 1'
author: 'Mauricio Vargas Sepulveda'
institution: 'University of Surrey'
year: 2025
format:
    html:
        theme: cosmo
        toc: true
        toc-location: left
        toc-title: "Contents"
        code-fold: false
        page-layout: full
        embed-resources: false
        self-contained: false
bibliography: ./bib/references.bib
csl: ../csl/chicago_manual_of_style_17th_edition_author_date.csl
---

# Problem

Recent headlines emphasize the challenges faced by central banks: inflation remains persistent in the U.S., global
supply chain uncertainties continue, and growth forecasts remain fragile amid geopolitical risks. 

# Goal

Provide policy recommendations for the Federal Reserve (Fed) new forecasting system.

# Before running the code

**Please please please open "problem-set-1.Rproj" in RStudio.**

**Do not open the QMD file directly or it can re-download all the datasets to the wrong directory.**

# GitHub repository

All the codes and data for this problem set are available in the GitHub repository: [https://github.com/pachadotdev/ecod025](https://github.com/pachadotdev/ecod025).

The zip file with the project is here: [https://github.com/pachadotdev/ecod025/archive/refs/heads/main.zip](https://github.com/pachadotdev/ecod025/archive/refs/heads/main.zip).

# Technical note

For this problem set, the models were written in C++ using the Armadillo library for linear algebra
[@sanderson16; @sanderson24].

To run the model functions, you need to change this boolean to "TRUE", otherwise when rendering the file it will
load pre-computed results.

```{r runmodels}
run_models <- T
reinstall_ecod025ps1 <- T
repos <- "https://cran.rstudio.com"
```

The functions were made available in the R package `ecod025ps1` which can be installed from this same repository:

```{r install, eval = TRUE, warning = FALSE, message = FALSE, echo = TRUE}
if (FALSE) {
  # devtools::install("../ecod025ps1/")
  if (reinstall_ecod025ps1) {
    if (require("ecod025ps1")) remove.packages("ecod025ps1")
  }
  
  if (!require("ecod025ps1") && run_models) {
    if (!require("cpp4r")) install.packages("cpp4r", repos = "https://pachadotdev.r-universe.dev")
    if (!require("armadillo4r")) install.packages("armadillo4r", repos = "https://pachadotdev.r-universe.dev")
    install.packages("ecod025ps1", repos = "https://pachadotdev.r-universe.dev")
  }
  
  if (!require("dynlm") && run_models) install.packages("dynlm", repos = repos)
}
```

```{r install2}
if (run_models) {
  library(ecod025ps1)
  library(dynlm)
}
```

R package for accessing the data:

```{r data1, warning = FALSE, message = FALSE, echo = TRUE}
if (!require("alfred")) {
  install.packages("alfred", repos = repos)
}
library(alfred)
```

Additional packages for data manipulation and plotting:

```{r rpkgs, warning = FALSE, message = FALSE, echo = TRUE}
if (!require("dplyr")) {
  install.packages("dplyr", repos = repos)
}
if (!require("lubridate")) {
  install.packages("lubridate", repos = repos)
}
if (!require("rlang")) {
  install.packages("rlang", repos = repos)
}
if (!require("purrr")) {
  install.packages("purrr", repos = repos)
}
if (!require("ggplot2")) {
  install.packages("ggplot2", repos = repos)
}
if (!require("tintin")) {
  install.packages("tintin", repos = repos)
}

library(dplyr)
library(lubridate)
library(rlang)
library(purrr)
library(ggplot2)
library(tintin)
```

# Models

## Vector Autoregressions (VAR)

$\text{VAR}(p)$ for inflation ($\pi_t$) and growth ($g_t$):

$$
y_t = A_1 y_{t-1} + \ldots + Ap y_{t-p} + u_t = A(L) y_t + u_t,\: y_t = [\pi_t, g_t]^T.
$$

## Factor-Augmented VAR (FA-VAR)

$$
\begin{aligned}
X_t &= \Lambda F_t + e_t, \cr
F_t &= \Phi_1 F_{t-1} + \ldots + \Phi_p F_{t-p} + v_t, \cr
y_t &= B(L)y_{t-1} + C(L)F_{t} + u_t
\end{aligned}
$$

## Dynamic Factor Model (DFM)

$$
\begin{aligned}
X_t &= \Lambda F_t + u_t,\: u_t \sim N(0, R), \cr
F_t &= AF_{t-1} + \eta_t,\: \eta_t \sim N(0, Q).
\end{aligned}
$$

For DFM, we consider VAR models that are identified and that can be written using lag polynomials such that besides $F_t$ lagged definition we have

$$
\begin{aligned}
A(L) F_t &= v_t \cr
B(L) u_t &= e_t,
\end{aligned}
$$

where $A(L)$ and $B(L)$ are lag polynomials with $p$ and $q$ lags, respectively [@hansen22].

To avoid identification issues, we will restrict the lag polynomial $B(L)$ to be diagonal.

Defining the inverse lag operators

$$
\begin{aligned}
D(L) &= A(L)^{-1} \cr
C(L) &= B(L)^{-1}
\end{aligned},
$$

then we have

$$
\begin{aligned}
X_t &= \Lambda F_t + u_t \cr
\implies C(L) X_t &= C(L) \Lambda F_t + C(L) u_t
\implies C(L) X_t &= C(L) \Lambda D(L) v_t + e_t \cr
\implies C(L) X_t &= \Lambda(L) v_t + e_t.
\end{aligned}
$$

Furthermore, we will restrict $\Lambda(L) = C(L) \Lambda D(L)$ to be a polynomial of $l$ lags.

The static form of the dynamic model is

$$
C(L) X_t = HV_t + e_t
$$

for a matrix $H$ with dimensions $N \times rl$ columns provided that $X_t$ and u_t$ are $N \times 1$, $\Lambda$ is $N \times r$ ($r < N$), and $F_t$ is $r \times 1$.

To avoid scaling issues, we will transform the elements of $X_t$ to have mean 0 and common variance.

## State-space representation

### Vector Autoregressions (VAR)

Model specification (reduced form):

  * $y_t = A(L) \cdot y_t + u_t$

State-space form (companion representation):

  * Observation:  $y_t = [I_K, 0, \ldots, 0] \cdot \chi_t + u_t$
  * Transition:   $\chi_t = F \cdot \chi_{t-1} + \eta_t$
  
where:
  - $\chi_t = [y_t', y_{t-1}', \ldots, y_{t-p+1}']'$ is the state vector ($Kp \times 1$) and $F$ is the companion matrix ($Kp \times Kp$)
  - $y_t$ is $K \times 1$ (observed variables)
  - $A_i$ are $K \times K$ (coefficient matrices for $i = 1, \ldots, p$)
  - $u_t \sim N(0, \Sigma)$ (error term)
  - $\Sigma$ is $K \times K$ (covariance matrix)

Estimation: Equation-by-equation OLS

### Factor-Augmented VAR (FA-VAR)

Model specification:

  * $X_t = \Lambda F_t + e_t$
  * $F_t = \Phi_1 F_{t-1} + \ldots + \Phi_p F_{t-p} + v_t$
  * $y_t = B(L) y_{t-1} + C(L) F_{t-1} + u_t$

where $X_t = [y_t, y_{t-1}, \ldots, y_{t-n}]$ is the information set constructed from current and lagged values of the target variable.

We use lagged factors $F_{t-1}$ (not contemporaneous $F_t$) in the augmented VAR to avoid data leakage, since $F_t$ is extracted from $X_t$ which contains $y_t$.

State-space form (companion representation):
  
  * Observation: $X_t = [\Lambda, 0, \ldots, 0] \cdot \chi_t + e_t$
  * Transition:  $\chi_t = A \cdot \chi_{t-1} + \eta_t$
  
where:
  - $\chi_t = [F_t', F_{t-1}', \ldots, F_{t-p+1}']'$ is the state vector and $A$ is the companion matrix for the factor VAR
  - $X_t$ is $N \times 1$ (information set: current and lagged $y$)
  - $F_t$ is $r \times 1$ (latent factors extracted from $X_t$, with $r < N$)
  - $y_t$ is $K \times 1$ (target variable of interest, $K=1$ for univariate)
  - $\Lambda$ is $N \times r$ (factor loadings)
  - $B(L) = B_1 L + \ldots + B_{p_y} L^{p_y}$ (lag polynomial for $y$ dynamics)
  - $\Phi(L) = \Phi_1 L + \ldots + \Phi_{p_f} L^{p_f}$ (lag polynomial for factor dynamics)
  - $C(L) = C_1 L + \ldots + C_{p_f} L^{p_f}$ (lag polynomial for factor impact on $y$)

Estimation: PCA for factor extraction, OLS for VARs

### Dynamic Factor Model (DFM)

Model specification (state-space form):

  * Observation equation:  $X_t = \Lambda \cdot F_t + u_t$,  $u_t \sim N(0, R)$
  * State equation:        $F_t = A \cdot F_{t-1} + \eta_t$, $\eta_t \sim N(0, Q)$

For VAR(p) factor dynamics, use companion form:

  * Observation:  $X_t = [\Lambda, 0, \ldots, 0] \cdot \chi_t + u_t$
  * Transition:   $\chi_t = A \cdot \chi_{t-1} + \eta_t$

where:
  - $\chi_t = [F_t', F_{t-1}', \ldots, F_{t-p+1}']'$ is the state vector ($rp \times 1$) and $A$ is the companion matrix ($rp \times rp$)
  - $X_t$ is $N \times 1$ (observed variables, standardized to mean 0, common variance)
  - $F_t$ is $r \times 1$ (latent factors, $r < N$)
  - $\Lambda$ is $N \times r$ (factor loadings)
  - $A$ is $r \times r$ (transition matrix for VAR(1)) or $rp \times rp$ (companion form for VAR(p))
  - $R$ is $N \times N$ (idiosyncratic covariance, diagonal)
  - $Q$ is $r \times r$ (factor innovation covariance) or $rp \times rp$ (companion form)

Estimation: EM algorithm with Kalman filter for state estimation

## Forecast Comparison Metrics

### Root Mean Squared Forecast Error (RMSFE)

$$
\text{RMSFE} = \sqrt{\frac{1}{T} \sum_{t=1}^{T} (y_{t+h} - \hat{y}_{t+h \mid t})^2}.
$$

### Mean Absolute Error (MAE)

$$
\text{MAE} = \frac{1}{T} \sum_{t=1}^{T} |y_{t+h} - \hat{y}_{t+h \mid t}|.
$$

# Data

Get the different series used to measure inflation according to
[FED](https://files.stlouisfed.org/files/htdocs/pageone-economics/uploads/Lessons/DataPracticeFRED_Measures_of_Inflation.pdf):

```{r data2, warning = FALSE, message = FALSE, echo = TRUE}
try(dir.create("data"), silent = TRUE)

download_data <- function(series_id) {
  fout <- paste0("data/", series_id, ".rds")
  if (!file.exists(fout)) {
    data <- get_alfred_series(series_id)
    data <- as_tibble(data)
    saveRDS(data, fout, compress = "xz")
  } else {
    data <- readRDS(fout)
  }
  return(data)
}

# Consumer Price Index for All Urban Consumers: All Items
cpiaucsl <- download_data("CPIAUCSL")

# Consumer Price Index for All Urban Consumers: All Items Less Food & Energy
cpilfesl <- download_data("CPILFESL")

# Consumer Price Index for All Urban Consumers: Energy
cpiengsl <- download_data("CPIENGSL")

# Consumer Price Index for All Urban Consumers: Food
cpifood <- download_data("CPIUFDSL")

# GDP Deflator
gdpdef <- download_data("GDPDEF")
```

Get the quarterly real GDP data to compute growth rates:

```{r data3, warning = FALSE, message = FALSE, echo = TRUE}
gdpc1 <- download_data("GDPC1")
```

We also require the 'University of Michigan\footnote{GO BLUE!}: Inflation Expectation (Median
expected price change next 12 months)' as a covariate for DFM:

```{r data4, warning = FALSE, message = FALSE, echo = TRUE}
# University of Michigan: Inflation Expectation (Median expected price change next 12 months)
michigan <- download_data("MICH")
```

# Data preparation

We need to filter and differentiate to get inflation rates as

$$
\text{Inflation Rate}_t = 100 \times \frac{C_t - C_{t-1}}{C_{t-1}}
$$

We will use October data to compute the inflation rate to match the reported quarterly GDP data.

```{r inflation, fig.width=6, fig.height=4, warning = FALSE, message = FALSE, echo = TRUE}
inflation_mm <- function(data, col) {
  data %>%
    as_tibble() %>%
    arrange(desc(date)) %>%
    # keep the most updated figure
    group_by(date) %>%
    filter(realtime_period == max(realtime_period)) %>%
    ungroup() %>%
    mutate(year = year(date), month = month(date)) %>%
    filter(month == 10) %>%
    mutate(
      inflation = 100 * (!!sym(col) - lead(!!sym(col))) / lead(!!sym(col))
    )
}

cpiaucsl_mm <- inflation_mm(cpiaucsl, "CPIAUCSL")
cpilfesl_mm <- inflation_mm(cpilfesl, "CPILFESL")
cpiengsl_mm <- inflation_mm(cpiengsl, "CPIENGSL")
cpifood_mm <- inflation_mm(cpifood, "CPIUFDSL")
gdpdef_mm <- inflation_mm(gdpdef, "GDPDEF")
```

The GDP data has a different frequency (quarterly) so we need to adjust the code:

```{r gdp, warning = FALSE, message = FALSE, echo = TRUE}
gdpc1_yy <- gdpc1 %>%
  arrange(desc(date)) %>%
  group_by(date) %>%
  filter(realtime_period == max(realtime_period)) %>%
  ungroup() %>%
  mutate(year = year(date)) %>%
  filter(year < 2025) %>%
  group_by(year) %>%
  summarise(gdp = sum(GDPC1), .groups = "drop") %>%
  mutate(
    date = ymd(paste0(year, "-10-01")),
    gdpgrowth = 100 * (gdp - lag(gdp)) / lag(gdp)
  )
```

UM data has a different format (it is already in percentage base 100 and lagged 1 year):

```{r michigan, warning = FALSE, message = FALSE, echo = TRUE}
michigan_mm <- michigan %>%
  arrange(desc(date)) %>%
  group_by(date) %>%
  filter(realtime_period == max(realtime_period)) %>%
  ungroup() %>%
  mutate(year = year(date), month = month(date)) %>%
  filter(month == 10) %>%
  mutate(date = date + years(1)) %>%
  rename(inflation = MICH)
```

Merge all into one data frame for plotting:

```{r plots, fig.width=6, fig.height=4, warning = FALSE, message = FALSE, echo = TRUE}
inflation <- map2_df(
  list(
    cpiaucsl_mm,
    cpilfesl_mm,
    cpiengsl_mm,
    cpifood_mm,
    gdpdef_mm,
    michigan_mm
  ),
  c("CPIAUCSL", "CPILFESL", "CPIENGSL", "CPIUFDSL", "GDPDEF", "MICH"),
  function(x, y) {
    x %>%
      select(date, value = inflation) %>%
      mutate(series = y)
  }
)
```

Plot of the different inflation measures:

```{r plots2, fig.width=6, fig.height=4, warning = FALSE, message = FALSE, echo = TRUE}
ggplot(inflation, aes(x = date, y = value, color = series)) +
  geom_line() +
  labs(
    title = "Inflation Measures",
    x = "Year",
    y = "Inflation rate (%)",
    color = "Series"
  ) +
  scale_colour_tintin_d() +
  facet_wrap(~series, ncol = 3) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "top") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed")

ggplot(gdpc1_yy, aes(x = date, y = gdpgrowth)) +
  geom_line() +
  labs(
    title = "Real GDP Change",
    x = "Year",
    y = "Growth rate (%)",
    color = "Series"
  ) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "top") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed")
```

The plots show some level of similarity between all series except for CPIENGSL (energy prices) which is more
volatile. The series without food and energy (CPILFESL) is more stable and is similar to the GDP deflator (GDPDEF) while
the other series have more volatility. The Michigan survey (MICH) shows a proper forward-looking measure of inflation
expectations.

Because energy depends on external factors (e.g., geopolitical events that affect oil prices) and food prices are
affected by seasonal patterns, we will use the CPILFESL and GDP deflator as our main inflation measure.

GDP is also affected by external factors (e.g., the $X - M$ component of GDP) but we do not have another measure of
GDP growth.

# Estimate a VAR model

The goal is to choose the lag length based on information criteria.

The first step is to determine the lag length using information criteria.

For CPILFESL and adapting from [Econometrics with R](https://www.econometrics-with-r.org/14.6-llsuic.html), which uses
BIC, we will use the AIC criterion.

$$
\text{AIC}(p) = \log \left( \frac{\text{SSR}(p)}{T} \right) + (p+1)\frac{2}{T}.
$$

```{r var1, eval = run_models, warning = FALSE, message = FALSE, echo = TRUE}
# compute AIC for AR model objects of class 'dynlm'
AIC <- function(model) {
  ssr <- sum(model$residuals^2)
  t <- length(model$residuals)
  npar <- length(model$coef)

  return(
    round(c("AIC" = log(ssr / t) + npar * 2 / t), 4)
  )
}

# intercept only AR model
AIC(dynlm(ts(cpilfesl_mm$inflation) ~ 1))
AIC(dynlm(ts(gdpc1_yy$gdpgrowth) ~ 1))
```

Looping over different model orders:

```{r var2, eval = run_models, warning = FALSE, message = FALSE, echo = TRUE}
# loop AIC over models of different orders
order <- 1:10

inflation_AICs <- vapply(
  order,
  function(x) {
    AIC(dynlm(
      ts(cpilfesl_mm$inflation) ~ L(ts(cpilfesl_mm$inflation), 1:x)
    ))
  },
  FUN.VALUE = numeric(1)
)

gdpdef_AICs <- vapply(
  order,
  function(x) {
    AIC(dynlm(ts(gdpdef_mm$inflation) ~ L(ts(gdpdef_mm$inflation), 1:x)))
  },
  FUN.VALUE = numeric(1)
)

gdpgrowth_AICs <- vapply(
  order,
  function(x) {
    AIC(dynlm(ts(gdpc1_yy$gdpgrowth) ~ L(ts(gdpc1_yy$gdpgrowth), 1:x)))
  },
  FUN.VALUE = numeric(1)
)

saveRDS(inflation_AICs, "data/aics_cpilfesl.rds")
saveRDS(gdpdef_AICs, "data/aics_gdpdef.rds")
saveRDS(gdpgrowth_AICs, "data/aics_gdpgrowth.rds")
```

```{r var2b, warning = FALSE, message = FALSE, echo = TRUE}
if (!run_models) {
  inflation_AICs <- readRDS("data/aics_cpilfesl.rds")
  gdpdef_AICs <- readRDS("data/aics_gdpdef.rds")
  gdpgrowth_AICs <- readRDS("data/aics_gdpgrowth.rds")
}

which.min(inflation_AICs)
which.min(gdpdef_AICs)
which.min(gdpgrowth_AICs)
```

Based on the AIC criterion, we select a lag length of:

* 4 for CPILFESL
* 6 for GDPDEF
* 4 for GDP growth

Now we can estimate the VAR model using `var_model()` from the `ecod025ps1` package:

```{r var4, warning = FALSE, message = FALSE, echo = TRUE}
# remove the last value as it is NA after the the lagged difference
h <- 12L
l1 <- 4L
l2 <- 6L
l3 <- 4L
```

The interesting exercise is to evaluate the forecasts from the VAR model by subsetting the data "T" years before the
end date and compare the predictions with the actual values. One problem in this time horizon is that we have the
COVID-19 pandemic (2020) external shock.

In other words, we will consider both in and out of sample model metrics. Because of the GDP data, we need to trim
the series before 2025.

```{r var5, warning = FALSE, message = FALSE, echo = TRUE}
common_years <- cpilfesl_mm %>%
  select(date) %>%
  inner_join(select(gdpdef_mm, date), by = "date") %>%
  inner_join(select(gdpc1_yy, date), by = "date")

# subset data
cpilfesl_mm_subset <- cpilfesl_mm %>%
  inner_join(common_years, by = "date") %>%
  filter(date <= (max(date) - years(h)))

gdpdef_mm_subset <- gdpdef_mm %>%
  inner_join(common_years, by = "date") %>%
  filter(date <= (max(date) - years(h)))

gdpc1_yy_subset <- gdpc1_yy %>%
  inner_join(common_years, by = "date") %>%
  filter(date <= (max(date) - years(h)))
```

```{r var5b, eval = run_models, warning = FALSE, message = FALSE, echo = TRUE}
fit_cpilfesl_subset <- var_model(
  na.omit(as.matrix(cpilfesl_mm_subset$inflation)),
  p = l1,
  include_const = TRUE,
  forecast_h = h
)

fit_gdpdef_subset <- var_model(
  na.omit(as.matrix(gdpdef_mm_subset$inflation)),
  p = l2,
  include_const = TRUE,
  forecast_h = h
)

fit_gdpgrowth_subset <- var_model(
  na.omit(as.matrix(gdpc1_yy_subset$gdpgrowth)),
  p = l3,
  include_const = TRUE,
  forecast_h = h
)

saveRDS(fit_cpilfesl_subset, "data/fit_cpilfesl_subset.rds")
saveRDS(fit_gdpdef_subset, "data/fit_gdpdef_subset.rds")
saveRDS(fit_gdpgrowth_subset, "data/fit_gdpgrowth_subset.rds")
```

```{r var5c, fig.width=6, fig.height=4, warning = FALSE, message = FALSE, echo = TRUE}
if (!run_models) {
  fit_cpilfesl_subset <- readRDS("data/fit_cpilfesl_subset.rds")
  fit_gdpdef_subset <- readRDS("data/fit_gdpdef_subset.rds")
  fit_gdpgrowth_subset <- readRDS("data/fit_gdpgrowth_subset.rds")
}

fit_predictions2 <- tibble(
  date = max(cpilfesl_mm_subset$date) +
    years(seq_len(fit_cpilfesl_subset$forecast_h)),
  prediction = as.numeric(fit_cpilfesl_subset$forecasts),
  series = "CPILFESL"
) %>%
  bind_rows(
    tibble(
      date = max(gdpdef_mm_subset$date) +
        years(seq_len(fit_gdpdef_subset$forecast_h)),
      prediction = as.numeric(fit_gdpdef_subset$forecasts),
      series = "GDPDEF"
    )
  ) %>%
  bind_rows(
    tibble(
      date = max(gdpc1_yy_subset$date) +
        years(seq_len(fit_gdpgrowth_subset$forecast_h)),
      prediction = as.numeric(fit_gdpgrowth_subset$forecasts),
      series = "GDPGROWTH"
    )
  )

fit_predictions2 <- fit_predictions2 %>%
  left_join(
    inflation %>%
      filter(series %in% c("CPILFESL", "GDPDEF")) %>%
      filter(year(date) > max(year(date) - h)) %>%
      rename(observed = value) %>%
      bind_rows(
        gdpc1_yy %>%
          filter(year(date) > max(year(date) - h)) %>%
          select(date, observed = gdpgrowth) %>%
          mutate(series = "GDPGROWTH")
      ),
    by = c("date", "series")
  )

ggplot(fit_predictions2) +
  geom_line(aes(x = date, y = observed, color = series), linewidth = 1.5) +
  geom_point(aes(x = date, y = observed, color = series), size = 3) +
  geom_line(
    aes(x = date, y = prediction, color = series),
    linewidth = 1,
    color = "gray70"
  ) +
  geom_point(
    data = fit_predictions2,
    aes(x = date, y = prediction, color = series),
    size = 2,
    color = "gray70"
  ) +
  geom_segment(
    data = fit_predictions2,
    aes(x = date, xend = date, y = observed, yend = prediction),
    linetype = "dashed",
    color = "gray50"
  ) +
  labs(
    title = "Observed Past Magnitudes vs VAR Predictions",
    subtitle = "Predictions in gray",
    x = "Date",
    y = "Change Rate (%)",
    color = "Series"
  ) +
  scale_colour_tintin_d() +
  facet_wrap(~series, ncol = 3) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "top") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed")
```

For the out-of-sample RMSFE and MAE metrics we need an R-side RMSFE and MAE functions as their C++
counterparts are not exported):

```{r var8, warning = FALSE, message = FALSE, echo = TRUE}
RMSFE <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2, na.rm = TRUE))
}

MAE <- function(actual, predicted) {
  mean(abs(actual - predicted), na.rm = TRUE)
}

fit_predictions2 %>%
  filter(series %in% c("CPILFESL", "GDPDEF", "GDPGROWTH")) %>%
  group_by(series) %>%
  summarise(
    RMSFE_out_of_sample = RMSFE(observed, prediction),
    MAE_out_of_sample = MAE(observed, prediction)
  ) %>%
  ungroup() %>%
  mutate(
    RMSFE_in_sample = c(
      fit_gdpgrowth_subset$rmsfe,
      fit_gdpdef_subset$rmsfe,
      fit_gdpgrowth_subset$rmsfe
    ),
    MAE_in_sample = c(
      fit_gdpgrowth_subset$mae,
      fit_gdpdef_subset$mae,
      fit_gdpgrowth_subset$mae
    )
  ) %>%
  select(
    series,
    RMSFE_in_sample,
    RMSFE_out_of_sample,
    MAE_in_sample,
    MAE_out_of_sample
  )
```

# Estimate a FA-VAR model

The FA-VAR model follows a pure time series approach: it creates an information set $X_t$ from the target variable
and its lags, extracts latent factors via PCA, and augments a VAR with these factors.

Model specification:
- $X_t = [y_t, y_{t-1}, \ldots, y_{t-L}]$ (information set created from y and its lags)
- Extract $r$ factors from $X_t$ using PCA
- Estimate: $y_t = B(L) y_{t-1} + C(L) F_t + u_t$ (augmented VAR with factor lags)

This approach captures nonlinear patterns in the autocorrelation structure through factor extraction.

```{r favar1, eval = run_models, warning = FALSE, message = FALSE, echo = TRUE}
# FA-VAR parameters (simplified to avoid overfitting)
n_lags <- 3L # Number of lags to create information set X (creates 4 variables)
n_factors <- 2L # Number of factors to extract from X
p_f <- 2L # Factor lags

y <- na.omit(as.matrix(cpilfesl_mm_subset$inflation))

# Estimate FA-VAR models
fit_cpilfesl_favar <- favar_model(
  y = y,
  n_lags = n_lags,
  n_factors = n_factors,
  p_y = l1,
  p_f = p_f,
  include_const = TRUE,
  forecast_h = h
)

# Tuned parameters for GDPDEF
n_lags <- 3L
n_factors <- 2L
p_f <- 1L

y <- na.omit(as.matrix(gdpdef_mm_subset$inflation))

fit_gdpdef_favar <- favar_model(
  y = y,
  n_lags = n_lags,
  n_factors = n_factors,
  p_y = l2,
  p_f = p_f,
  include_const = TRUE,
  forecast_h = h
)

# Tuned parameters for GDP growth
n_lags <- 3L
n_factors <- 2L
p_f <- 1L

y <- na.omit(as.matrix(gdpc1_yy_subset$gdpgrowth))

fit_gdpc1_favar <- favar_model(
  y = y,
  n_lags = n_lags,
  n_factors = n_factors,
  p_y = l3,
  p_f = p_f,
  include_const = TRUE,
  forecast_h = h
)

saveRDS(fit_cpilfesl_favar, "data/fit_cpilfesl_favar.rds")
saveRDS(fit_gdpdef_favar, "data/fit_gdpdef_favar.rds")
saveRDS(fit_gdpc1_favar, "data/fit_gdpc1_favar.rds")
```

```{r favar2, warning = FALSE, message = FALSE, echo = TRUE}
if (!run_models) {
  fit_cpilfesl_favar <- readRDS("data/fit_cpilfesl_favar.rds")
  fit_gdpdef_favar <- readRDS("data/fit_gdpdef_favar.rds")
  fit_gdpc1_favar <- readRDS("data/fit_gdpc1_yy_favar.rds")
}

fit_predictions3 <- tibble(
  date = max(cpilfesl_mm_subset$date) +
    years(seq_len(fit_cpilfesl_favar$forecast_horizon)),
  prediction = as.numeric(fit_cpilfesl_favar$forecasts),
  series = "CPILFESL"
) %>%
  bind_rows(
    tibble(
      date = max(gdpdef_mm_subset$date) +
        years(seq_len(fit_gdpdef_favar$forecast_horizon)),
      prediction = as.numeric(fit_gdpdef_favar$forecasts),
      series = "GDPDEF"
    )
  ) %>%
  bind_rows(
    tibble(
      date = max(gdpc1_yy_subset$date) +
        years(seq_len(fit_gdpc1_favar$forecast_horizon)),
      prediction = as.numeric(fit_gdpc1_favar$forecasts),
      series = "GDPGROWTH"
    )
  )

fit_predictions3 <- fit_predictions3 %>%
  left_join(
    inflation %>%
      filter(series %in% c("CPILFESL", "GDPDEF")) %>%
      filter(year(date) > max(year(date) - h)) %>%
      select(date, observed = value, series) %>%
      bind_rows(
        gdpc1_yy %>%
          filter(year(date) > max(year(date) - h)) %>%
          select(date, observed = gdpgrowth) %>%
          mutate(series = "GDPGROWTH")
      ),
    by = c("date", "series")
  )

fit_predictions3 %>%
  filter(series %in% c("CPILFESL", "GDPDEF", "GDPGROWTH")) %>%
  group_by(series) %>%
  summarise(
    RMSFE_out_of_sample = RMSFE(observed, prediction),
    MAE_out_of_sample = MAE(observed, prediction)
  ) %>%
  ungroup() %>%
  mutate(
    RMSFE_in_sample = c(
      fit_cpilfesl_favar$rmsfe,
      fit_gdpdef_favar$rmsfe,
      fit_gdpc1_favar$rmsfe
    ),
    MAE_in_sample = c(
      fit_cpilfesl_favar$mae,
      fit_gdpdef_favar$mae,
      fit_gdpc1_favar$mae
    )
  ) %>%
  select(
    series,
    RMSFE_in_sample,
    RMSFE_out_of_sample,
    MAE_in_sample,
    MAE_out_of_sample
  )
```

Plot the FA-VAR forecasts on the censored data:

```{r favar3, fig.width=6, fig.height=4, warning = FALSE, message = FALSE, echo = TRUE}
ggplot(fit_predictions3) +
  geom_line(aes(x = date, y = observed, color = series), linewidth = 1.5) +
  geom_point(aes(x = date, y = observed, color = series), size = 3) +
  geom_line(
    aes(x = date, y = prediction, color = series),
    linewidth = 1,
    color = "gray70"
  ) +
  geom_point(
    aes(x = date, y = prediction, color = series),
    size = 2,
    color = "gray70"
  ) +
  geom_segment(
    aes(x = date, xend = date, y = observed, yend = prediction),
    linetype = "dashed",
    color = "gray50"
  ) +
  labs(
    title = "Observed Past Magnitudes vs FA-VAR Predictions",
    subtitle = "Predictions in gray",
    x = "Date",
    y = "Change Rate (%)",
    color = "Series"
  ) +
  scale_colour_tintin_d() +
  facet_wrap(~series, ncol = 3) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "top")
```

# Estimate a DFM model

The DFM uses a state-space representation with PCA initialization and Kalman filter for parameter estimation.

DFM is designed for multivariate data where we want to extract common factors across different economic variables.
Unlike FA-VAR (which uses autoregressive lags), DFM works best with actual multivariate series that share common dynamics.

We'll use two inflation measures $[CPILFESL/GDPDEF, CPIFOOD]$ to extract common factors.

```{r dfm1, eval = run_models, warning = FALSE, message = FALSE, echo = TRUE}
dfm_data_cpilfesl <- cpilfesl_mm_subset %>%
  select(date, cpilfesl = inflation) %>%
  inner_join(
    cpifood_mm %>% select(date, cpifood = inflation),
    by = "date"
  ) %>%
  na.omit()

x_cpilfesl_dfm <- as.matrix(dfm_data_cpilfesl[, c("cpilfesl", "cpifood")])

# Estimate DFM (1 common inflation factor from 2 variables)
fit_cpilfesl_dfm <- dfm_model(
  x = x_cpilfesl_dfm,
  n_factors = 1L,
  p = 1L,
  max_iter = 50L,
  tol = 1e-6,
  forecast_h = h
)

dfm_data_gdpdef <- gdpdef_mm_subset %>%
  select(date, gdpdef = inflation) %>%
  inner_join(
    cpifood_mm %>% select(date, cpifood = inflation),
    by = "date"
  ) %>%
  na.omit()

x_gdpdef_dfm <- as.matrix(dfm_data_gdpdef[, c("gdpdef", "cpifood")])

fit_gdpdef_dfm <- dfm_model(
  x = x_gdpdef_dfm,
  n_factors = 1L,
  p = 1L,
  max_iter = 50L,
  tol = 1e-6,
  forecast_h = h
)

dfm_data_gdpc1 <- gdpc1_yy_subset %>%
  select(date, gdpgrowth = gdpgrowth) %>%
  inner_join(
    cpifood_mm %>% select(date, cpifood = inflation),
    by = "date"
  ) %>%
  na.omit()

x_gdpc1_dfm <- as.matrix(dfm_data_gdpc1[, c("gdpgrowth", "cpifood")])

fit_gdpc1_dfm <- dfm_model(
  x = x_gdpc1_dfm,
  n_factors = 1L,
  p = 2L,
  max_iter = 50L,
  tol = 1e-6,
  forecast_h = h
)

saveRDS(fit_cpilfesl_dfm, "data/fit_cpilfesl_dfm.rds")
saveRDS(fit_gdpdef_dfm, "data/fit_gdpdef_dfm.rds")
saveRDS(fit_gdpc1_dfm, "data/fit_gdpc1_dfm.rds")
```

```{r dfm2, warning = FALSE, message = FALSE, echo = TRUE}
if (!run_models) {
  fit_cpilfesl_dfm <- readRDS("data/fit_cpilfesl_dfm.rds")
  fit_gdpdef_dfm <- readRDS("data/fit_gdpdef_dfm.rds")
  fit_gdpc1_dfm <- readRDS("data/fit_gdpc1_dfm.rds")
}

# Extract forecasts for the FIRST variable only (our target)
# DFM forecasts all variables, but we only want the first one
fit_predictions4 <- tibble(
  date = max(dfm_data_cpilfesl$date) +
    years(seq_len(fit_cpilfesl_dfm$forecast_horizon)),
  prediction = as.numeric(fit_cpilfesl_dfm$forecasts[, 1]), # First column is CPILFESL
  series = "CPILFESL"
) %>%
  bind_rows(
    tibble(
      date = max(dfm_data_gdpdef$date) +
        years(seq_len(fit_gdpdef_dfm$forecast_horizon)),
      prediction = as.numeric(fit_gdpdef_dfm$forecasts[, 1]), # First column is GDPDEF
      series = "GDPDEF"
    )
  ) %>%
  bind_rows(
    tibble(
      date = max(dfm_data_gdpc1$date) +
        years(seq_len(fit_gdpc1_dfm$forecast_horizon)),
      prediction = as.numeric(fit_gdpc1_dfm$forecasts[, 1]), # First column is GDP growth
      series = "GDPGROWTH"
    )
  )

fit_predictions4 <- fit_predictions4 %>%
  left_join(
    inflation %>%
      filter(series %in% c("CPILFESL", "GDPDEF")) %>%
      filter(year(date) > max(year(date) - h)) %>%
      select(date, observed = value, series) %>%
      bind_rows(
        gdpc1_yy %>%
          filter(year(date) > max(year(date) - h)) %>%
          select(date, observed = gdpgrowth) %>%
          mutate(series = "GDPGROWTH")
      ),
    by = c("date", "series")
  )

fit_predictions4 %>%
  filter(series %in% c("CPILFESL", "GDPDEF", "GDPGROWTH")) %>%
  group_by(series) %>%
  summarise(
    RMSFE_out_of_sample = RMSFE(observed, prediction),
    MAE_out_of_sample = MAE(observed, prediction)
  ) %>%
  ungroup() %>%
  mutate(
    RMSFE_in_sample = c(fit_cpilfesl_dfm$rmsfe, fit_gdpdef_dfm$rmsfe, fit_gdpc1_dfm$rmsfe),
    MAE_in_sample = c(fit_cpilfesl_dfm$mae, fit_gdpdef_dfm$mae, fit_gdpc1_dfm$mae)
  ) %>%
  select(
    series,
    RMSFE_in_sample,
    RMSFE_out_of_sample,
    MAE_in_sample,
    MAE_out_of_sample
  )
```

Now we can plot the forecast on the censored data:

```{r dfm3, fig.width=6, fig.height=4, warning = FALSE, message = FALSE, echo = TRUE}
ggplot(fit_predictions4) +
  geom_line(
    aes(x = date, y = observed, color = series),
    linewidth = 1.5
  ) +
  geom_point(
    aes(x = date, y = observed, color = series),
    size = 3
  ) +
  geom_line(
    aes(x = date, y = prediction, color = series),
    linewidth = 1,
    color = "gray70"
  ) +
  geom_point(
    aes(x = date, y = prediction, color = series),
    size = 2,
    color = "gray70"
  ) +
  geom_segment(
    data = fit_predictions4,
    aes(x = date, xend = date, y = observed, yend = prediction),
    linetype = "dashed",
    color = "gray50"
  ) +
  labs(
    title = "Inflation Measures and Past DFM Predictions",
    subtitle = "Predictions in gray",
    x = "Date",
    y = "Inflation Rate (%)",
    color = "Series"
  ) +
  scale_colour_tintin_d() +
  facet_wrap(~series, ncol = 3) +
  theme_minimal(base_size = 10) +
  theme(legend.position = "top") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed")
```

# Model Comparison

# C++ codes

